import React, { useState, useRef, useEffect } from 'react';
import { 
  Camera, Command, Copy, Settings, AlertCircle, Image as ImageIcon, 
  BookOpen, Lightbulb, X, ExternalLink, ChevronDown, Clapperboard, 
  Info, GraduationCap, Plus, Menu, ArrowRight, DollarSign, Unlock, 
  Monitor, Cpu, Download, Key, Layers, Aperture, Video, Wrench, 
  ShieldAlert, Link as LinkIcon, Maximize, Sliders, Eye, Mail, 
  Send, Brain, Sparkles, Globe, Book, Activity, Search
} from 'lucide-react';

const PocketCinemaApp = () => {
  // --- STATE MANAGEMENT ---
  const [currentView, setCurrentView] = useState('generator');
  const [apiKey, setApiKey] = useState('');
  const [showSettings, setShowSettings] = useState(false);
  const [images, setImages] = useState([]); 
  const [userRequest, setUserRequest] = useState('');
  const [platform, setPlatform] = useState('Nano-Banana');
  
  // Generation Results
  const [result, setResult] = useState(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const [copied, setCopied] = useState(false);
  
  // Troubleshooting State
  const [troubleInput, setTroubleInput] = useState('');
  const [troubleResult, setTroubleResult] = useState(null);
  const [troubleLoading, setTroubleLoading] = useState(false);

  // Get The Look State
  const [lookImage, setLookImage] = useState(null);
  const [lookBase64, setLookBase64] = useState(null);
  const [lookResult, setLookResult] = useState(null);
  const [lookLoading, setLookLoading] = useState(false);

  // Contact Form State
  const [contactName, setContactName] = useState('');
  const [contactEmail, setContactEmail] = useState('');
  const [contactSubject, setContactSubject] = useState('');
  const [contactMessage, setContactMessage] = useState('');

  const [isMobileMenuOpen, setIsMobileMenuOpen] = useState(false);
  const [draggedImageIndex, setDraggedImageIndex] = useState(null);
  
  const fileInputRef = useRef(null);
  const lookInputRef = useRef(null);
  const GENERATION_DATE = "December 17, 2025";

  // --- EFFECTS ---
  useEffect(() => {
    const storedKey = localStorage.getItem('gemini_user_api_key');
    if (storedKey) setApiKey(storedKey);
  }, []);

  // --- HANDLERS ---
  const handleSaveKey = (e) => {
    const key = e.target.value;
    setApiKey(key);
    localStorage.setItem('gemini_user_api_key', key);
  };

  const handleImageUpload = (e) => {
    const files = Array.from(e.target.files);
    if (images.length + files.length > 10) {
      setError("Maximum of 10 images allowed per reel.");
      return;
    }
    const newImages = [];
    files.forEach(file => {
      if (file.size > 5 * 1024 * 1024) {
        setError("Some images skipped (Must be under 5MB).");
        return;
      }
      const reader = new FileReader();
      reader.onloadend = () => {
        setImages(prev => [...prev, { url: reader.result, base64: reader.result.split(',')[1] }]);
        setError('');
        setResult(null);
      };
      reader.readAsDataURL(file);
    });
  };

  const handleLookUpload = (e) => {
    const file = e.target.files[0];
    if (file) {
        if (file.size > 5 * 1024 * 1024) {
            setError("Image must be under 5MB.");
            return;
        }
        const reader = new FileReader();
        reader.onloadend = () => {
            setLookImage(reader.result);
            setLookBase64(reader.result.split(',')[1]);
            setLookResult(null);
        };
        reader.readAsDataURL(file);
    }
  };

  const removeImage = (index) => setImages(prev => prev.filter((_, i) => i !== index));
  
  const clearImages = () => {
    setImages([]);
    setResult(null);
    if (fileInputRef.current) fileInputRef.current.value = '';
  };

  // Drag and Drop Handlers
  const handleDragStart = (index) => setDraggedImageIndex(index);
  const handleDragOver = (e) => e.preventDefault();
  const handleDrop = (index) => {
    if (draggedImageIndex === null) return;
    const newImages = [...images];
    const draggedImage = newImages[draggedImageIndex];
    newImages.splice(draggedImageIndex, 1);
    newImages.splice(index, 0, draggedImage);
    setImages(newImages);
    setDraggedImageIndex(null);
  };

  const handleContactSubmit = (e) => {
    e.preventDefault();
    const subjectPrefix = "[Pocket Cinema]";
    const fullSubject = `${subjectPrefix} ${contactSubject}`;
    const body = `Name: ${contactName}\nEmail: ${contactEmail}\n\nMessage:\n${contactMessage}`;
    window.location.href = `mailto:nhp2media@gmail.com?subject=${encodeURIComponent(fullSubject)}&body=${encodeURIComponent(body)}`;
  };

  const generateOptimizedPrompt = async () => {
    if (!apiKey) { setError("API Key missing. Click Settings to add it."); setShowSettings(true); return; }
    if (images.length === 0) { setError("Please upload at least one image."); return; }
    if (!userRequest) { setError("Please describe your request."); return; }

    setLoading(true); setError(''); setResult(null); setTroubleResult(null);

    try {
      const parts = [
        {
          text: `You are the AI Director and Instructor for 'Pocket Cinema x Nathan Histed'.
          INPUT: 1. Attached Images (${images.length}). 2. Request: "${userRequest}". 3. Platform: "${platform}".
          TASK: Analyze images (composition, lighting, style). Create a prompt that REPLICATES the style but incorporates the Request.
          EDUCATIONAL GOAL: Define technical jargon in "Reasoning". When you explain a term, explain WHY it matters.
          PLATFORM SPECS:
          - Nano-Banana: detailed, natural language. "Create a photorealistic image of..."
          - Midjourney: --ar, --v 6.0, --style raw, descriptors.
          - DALL-E 3: rich, natural sentences.
          - Stable Diffusion: weights (keyword:1.2), tags.
          - Flux: Natural language, focus on texture and lighting.
          OUTPUT JSON: { "prompt": "...", "reasoning": "...", "takeaways": ["..."] }`
        }
      ];
      images.forEach(img => parts.push({ inline_data: { mime_type: "image/jpeg", data: img.base64 } }));

      const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${apiKey}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ contents: [{ parts: parts }] })
      });

      const data = await response.json();
      if (data.error) throw new Error(data.error.message);
      let textResponse = data.candidates?.[0]?.content?.parts?.[0]?.text;
      if (!textResponse) throw new Error("No response generated.");
      const parsedResult = JSON.parse(textResponse.replace(/```json/g, '').replace(/```/g, '').trim());
      setResult(parsedResult);
    } catch (err) {
      console.error(err);
      setError("Failed to generate. Check API Key or try again.");
    } finally {
      setLoading(false);
    }
  };

  const analyzeLook = async () => {
    if (!apiKey) { setError("API Key missing."); setShowSettings(true); return; }
    if (!lookBase64) { setError("Upload an image first."); return; }
    setLookLoading(true);
    try {
        const payload = {
            contents: [{
                parts: [
                    {
                        text: `You are a Reverse-Engineering Specialist for AI Imagery.
                        TASK: Analyze the attached image in extreme detail.
                        GOAL: Provide a "Master Prompt" that would allow a user to regenerate this exact image style and likeness.
                        OUTPUT JSON: { "master_prompt": "...", "breakdown": { "subject": "...", "lighting": "...", "camera": "...", "style": "..." }, "education": "..." }`
                    },
                    { inline_data: { mime_type: "image/jpeg", data: lookBase64 } }
                ]
            }]
        };
        const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${apiKey}`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(payload)
        });
        const data = await response.json();
        if (data.error) throw new Error(data.error.message);
        let textResponse = data.candidates?.[0]?.content?.parts?.[0]?.text;
        const parsedResult = JSON.parse(textResponse.replace(/```json/g, '').replace(/```/g, '').trim());
        setLookResult(parsedResult);
    } catch(err) { console.error(err); setError("Analysis failed."); } finally { setLookLoading(false); }
  };

  const troubleshootPrompt = async () => {
    if (!apiKey) return;
    if (!troubleInput) return;
    setTroubleLoading(true);
    try {
       const payload = {
        contents: [{
            parts: [{
                text: `You are a Technical Troubleshooter.
                CONTEXT: Platform: ${platform}, Original Prompt: "${result.prompt}", Issue: "${troubleInput}"
                OUTPUT JSON: { "diagnosis": "...", "fix_action": "...", "revised_prompt": "..." }`
            }]
        }]
       };
      const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${apiKey}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload)
      });
      const data = await response.json();
      if (data.error) throw new Error(data.error.message);
      let textResponse = data.candidates?.[0]?.content?.parts?.[0]?.text;
      const parsedResult = JSON.parse(textResponse.replace(/```json/g, '').replace(/```/g, '').trim());
      setTroubleResult(parsedResult);
    } catch (err) { console.error(err); } finally { setTroubleLoading(false); }
  };

  const copyText = (text) => {
    if (text) {
      const textArea = document.createElement("textarea");
      textArea.value = text;
      document.body.appendChild(textArea);
      textArea.select();
      document.execCommand('copy');
      setCopied(true);
      setTimeout(() => setCopied(false), 2000);
      document.body.removeChild(textArea);
    }
  };

  // --- GLOSSARY DATA ---
  const glossaryTerms = [
    { term: "Artifacts", definition: "Weird mistakes in the picture. Like when a hand has 6 fingers or a face looks melted. It's 'junk data'." },
    { term: "Aspect Ratio", definition: "The shape of the picture. Square (1:1), Phone Screen (9:16), or TV Screen (16:9)." },
    { term: "Bokeh", definition: "That nice blurry background effect you see in professional portraits. It helps the person stand out." },
    { term: "Checkpoint", definition: "The main 'Brain' file of the AI. Different files are good at different things (e.g., one for cartoons, one for photos)." },
    { term: "CFG Scale", definition: "The 'Listening Slider'. Low numbers = The AI ignores you and improvises. High numbers = It follows your instructions strictly." },
    { term: "Denoising Strength", definition: "How much to change an image. 0.1 = Tiny tweak. 1.0 = Completely new image." },
    { term: "Diffusion", definition: "How AI creates art. It starts with static (noise) and slowly cleans it up until it finds a picture." },
    { term: "Embedding", definition: "A tiny file you teach the AI. Like teaching it what 'Nathan' looks like so you don't have to describe him every time." },
    { term: "Guidance Scale", definition: "Another name for CFG Scale. It guides how closely the AI sticks to your words." },
    { term: "Hallucination", definition: "When the AI makes up stuff you didn't ask for. Like adding a hat when you didn't say 'hat'." },
    { term: "Hyperrealistic", definition: "Looks *more* real than a photo. Everything is perfectly sharp. Often used in commercials." },
    { term: "Image-to-Image (i2i)", definition: "Starting with a picture instead of just text. Using a sketch as a guide." },
    { term: "Inpainting", definition: "Digital erasing. You color over a mistake (like a bad hand) and tell the AI to re-draw just that spot." },
    { term: "Latent Space", definition: "The mathematical map where the AI stores concepts. 'Cat' and 'Dog' are close together on this map." },
    { term: "LoRA", definition: "A 'Style Filter'. A small file you add to make the AI draw in a specific style (like Anime or Clay) without changing its whole brain." },
    { term: "Negative Prompt", definition: "The 'Do Not' list. You tell the AI what to avoid, like 'blurry', 'ugly', or 'bad hands'." },
    { term: "Noise", definition: "The random static (like an old TV screen) that the AI starts with before it draws." },
    { term: "Outpainting", definition: "Zooming out. The AI invents new surroundings that weren't in the original photo." },
    { term: "Parameter", definition: "Settings/Dials. Like 'Volume' or 'Brightness', but for 'Creativity' or 'Chaos'." },
    { term: "Photorealistic", definition: "Looks like a real photo. It might have natural flaws like grain or slight blur, making it feel authentic." },
    { term: "Prompt", definition: "The text recipe you give the AI to cook up an image." },
    { term: "Seed", definition: "The ID number of an image. If you use the same Seed and Prompt, you get the exact same image again." },
    { term: "Steps", definition: "Layers of polish. The AI draws in loops. 30 steps is usually a finished painting. 5 steps is a rough sketch." },
    { term: "Text-to-Image (t2i)", definition: "Making a picture from scratch using only words." },
    { term: "Token", definition: "How AI counts words. A long word might be 3 tokens. AI has a memory limit of how many tokens it can hold." },
    { term: "Upscale", definition: "Making a small picture bigger and sharper by guessing the missing details." },
    { term: "VRAM", definition: "Video Memory. The muscle of your computer's graphics card. You need a lot of this to run AI at home." },
    { term: "Weights", definition: "Importance. Telling the AI that (Cat:1.5) is more important than (Sitting:1.0)." }
  ];

  const top10List = [
    { rank: 1, name: "Midjourney v6.1", type: "Discord / Web", status: "PAID", cost: "$10 - $30 / month", why: "The gold standard for cinematic aesthetics.", url: "https://www.midjourney.com", workaround: "Use Tensor.art or SeaArt.ai.", workaroundLinks: [{ label: "Tensor.art", url: "https://tensor.art" }, { label: "SeaArt.ai", url: "https://www.seaart.ai" }] },
    { rank: 2, name: "Flux.1 (Dev)", type: "Open Weights", status: "FREE TO TRY", cost: "Free locally / Paid via Cloud API", why: "The new king of realism and text rendering.", url: "https://blackforestlabs.ai", localInfo: "Runs on your computer. Requires NVIDIA GPU (12GB+). Use 'Pinokio'.", localLinks: [{ label: "Get Pinokio", url: "https://pinokio.computer" }], workaround: "Use Civitai or Tensor for free cloud runs.", workaroundLinks: [{ label: "Run on Civitai", url: "https://civitai.com" }] },
    { rank: 3, name: "Stable Diffusion 3.5", type: "Local / Web UI", status: "COMPLETELY FREE", cost: "$0 (If running locally)", why: "Total control. Using 'ControlNet', you can map exact poses.", url: "https://stability.ai", localInfo: "Runs on PC (8GB+ VRAM). Use Stability Matrix.", localLinks: [{ label: "Get Stability Matrix", url: "https://github.com/LykosAI/StabilityMatrix" }], workaround: "Run in browser:", workaroundLinks: [{ label: "Civitai Generator", url: "https://civitai.com/generate" }] },
    { rank: 4, name: "Gemini (Nano-Banana)", type: "Google Cloud", status: "COMPLETELY FREE", cost: "$0 (via AI Studio)", why: "The engine powering this app. Massive context window.", url: "https://aistudio.google.com", workaround: "Use Developer Studio:", workaroundLinks: [{ label: "Open AI Studio", url: "https://aistudio.google.com" }] },
    { rank: 5, name: "DALL-E 3", type: "Web / App", status: "PAID (Usually)", cost: "$20/mo (ChatGPT Plus)", why: "Best for complex logic and typography.", url: "https://chatgpt.com", workaround: "Free via Microsoft:", workaroundLinks: [{ label: "Bing Image Creator", url: "https://www.bing.com/images/create" }] },
    { rank: 6, name: "Leonardo.ai", type: "Web Platform", status: "FREEMIUM", cost: "150 Daily Free Credits", why: "User-friendly interface for those who find Stable Diffusion too technical.", url: "https://leonardo.ai", workaround: "If out of credits:", workaroundLinks: [{ label: "Playground.com", url: "https://playground.com" }] },
    { rank: 7, name: "Krea AI", type: "Real-time Web", status: "FREEMIUM", cost: "Limited Daily Runs", why: "Real-time enhancement.", url: "https://www.krea.ai", workaround: "Free alternative:", workaroundLinks: [{ label: "PromeAI", url: "https://www.promeai.com" }] },
    { rank: 8, name: "Magnific AI", type: "Upscaler", status: "EXPENSIVE", cost: "$39/mo+", why: "It 'hallucinates' details into low-res images.", url: "https://magnific.ai", workaround: "Free local alternative:", workaroundLinks: [{ label: "Download Upscayl", url: "https://upscayl.org" }] },
    { rank: 9, name: "Adobe Firefly", type: "Photoshop / Web", status: "FREEMIUM", cost: "25 Monthly Credits (Free)", why: "Ethical choice. Trained only on stock images.", url: "https://firefly.adobe.com", workaround: "Free tier via Express:", workaroundLinks: [{ label: "Adobe Express", url: "https://new.express.adobe.com" }] },
    { rank: 10, name: "Runway (Gen-3 Alpha)", type: "Web Suite", status: "PAID / FREEMIUM", cost: "Limited Trials", why: "Known for video, excellent for storyboarding.", url: "https://runwayml.com", workaround: "Generous free tiers elsewhere:", workaroundLinks: [{ label: "Kling AI", url: "https://klingai.com" }] }
  ];

  const platformInfo = {
    "Nano-Banana": { title: "Gemini Flash (Nano-Banana)", definition: "Google's high-speed vision model.", bestFor: "Rapid prototyping & logic.", habit: "Conversational but precise." },
    "Midjourney": { title: "Midjourney v6", definition: "Artistic AI via Discord.", bestFor: "Cinematic aesthetics.", habit: "Use --ar and --stylize." },
    "DALL-E 3": { title: "DALL-E 3", definition: "OpenAI's chat-integrated model.", bestFor: "Typography & complex logic.", habit: "Be extremely descriptive." },
    "Stable Diffusion": { title: "Stable Diffusion", definition: "Open-source, controllable engine.", bestFor: "Deep manipulation & ControlNet.", habit: "Use (weights) and tags." },
    "Flux.1": { title: "Flux (Black Forest Labs)", definition: "The new open-weight king of realism.", bestFor: "Photorealism & text rendering.", habit: "Natural language, focus on lighting." },
    "Gemini Imagen": { title: "Imagen 3", definition: "Google's high-fidelity model.", bestFor: "Commercial stock quality.", habit: "Describe textures." },
    "Meta AI": { title: "Meta / Llama", definition: "Social-first AI.", bestFor: "Stickers & speed.", habit: "Short and punchy." }
  };

  // --- SUB-COMPONENTS ---

  const Navigation = () => (
    <nav className="border-b-4 border-black bg-white sticky top-0 z-50">
      <div className="max-w-7xl mx-auto px-4 lg:px-6 h-20 flex justify-between items-center">
        <div onClick={() => setCurrentView('generator')} className="flex items-center gap-3 cursor-pointer hover:opacity-70 transition-opacity">
          <div className="bg-black text-white p-2"><Clapperboard className="w-6 h-6" /></div>
          <div><h1 className="text-lg lg:text-xl font-black uppercase tracking-tighter leading-none">Pocket Cinema</h1><p className="text-[10px] font-bold uppercase tracking-[0.2em] text-gray-500">x Nathan Histed</p></div>
        </div>
        <div className="hidden xl:flex gap-4 2xl:gap-6">
          {[
            { id: 'generator', label: 'Generator' },
            { id: 'get-look', label: 'Get The Look' },
            { id: 'how-it-works', label: 'How It Works' },
            { id: 'glossary', label: 'Glossary' },
            { id: 'vault', label: 'The Vault' },
            { id: 'top10', label: 'The Top 10' },
            { id: 'contact', label: 'Reach Out' },
            { id: 'whois', label: 'Who We Are' },
          ].map(item => (
            <button key={item.id} onClick={() => setCurrentView(item.id)} className={`text-[10px] 2xl:text-xs font-bold uppercase tracking-widest hover:text-black transition-colors ${currentView === item.id ? 'text-black underline decoration-4 underline-offset-8' : 'text-gray-400'}`}>{item.label}</button>
          ))}
        </div>
        <button className="xl:hidden" onClick={() => setIsMobileMenuOpen(!isMobileMenuOpen)}><Menu className="w-8 h-8" /></button>
      </div>
      {isMobileMenuOpen && (
        <div className="xl:hidden border-t-2 border-black bg-gray-50 p-4 flex flex-col gap-4">
           {[
            { id: 'generator', label: 'Generator' },
            { id: 'get-look', label: 'Get The Look' },
            { id: 'how-it-works', label: 'How It Works' },
            { id: 'glossary', label: 'AI Glossary' },
            { id: 'vault', label: 'The Vault' },
            { id: 'top10', label: 'The Top 10' },
            { id: 'contact', label: 'Reach Out' },
            { id: 'whois', label: 'Who We Are' },
          ].map(item => <button key={item.id} onClick={() => { setCurrentView(item.id); setIsMobileMenuOpen(false); }} className={`text-left text-sm font-bold uppercase tracking-widest py-2 ${currentView === item.id ? 'text-black border-l-4 border-black pl-3' : 'text-gray-400 pl-4'}`}>{item.label}</button>)}
        </div>
      )}
    </nav>
  );

  const GlossaryView = () => (
    <div className="max-w-5xl mx-auto space-y-8 animate-in fade-in slide-in-from-bottom-4">
        <div className="text-center mb-10">
            <h2 className="text-5xl font-black uppercase tracking-tighter mb-2">AI Glossary</h2>
            <p className="text-xl font-bold uppercase tracking-widest text-gray-400">Plain English Definitions</p>
        </div>
        <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
            {glossaryTerms.map((item, index) => (
                <div key={index} className="border-2 border-black bg-white p-6 hover:bg-gray-50 transition-colors">
                    <h3 className="font-black uppercase text-lg mb-2 flex items-center gap-2">
                        <Book className="w-5 h-5 text-gray-400" /> {item.term}
                    </h3>
                    <p className="text-sm font-medium text-gray-700 leading-relaxed">
                        {item.definition}
                    </p>
                </div>
            ))}
        </div>
    </div>
  );

  const GeneratorView = () => (
    <div className="grid grid-cols-1 lg:grid-cols-12 gap-10 animate-in fade-in duration-500">
      <div className="lg:col-span-5 space-y-8">
        <div className="flex justify-end">
             <button onClick={() => setShowSettings(!showSettings)} className="text-xs font-bold uppercase flex items-center gap-2 hover:underline"><Settings className="w-4 h-4" /> Production Settings</button>
        </div>
        {showSettings && (
          <div className="p-6 border-4 border-black bg-gray-50">
            <h3 className="text-sm font-bold mb-4 uppercase">API Configuration</h3>
            <input type="password" value={apiKey} onChange={handleSaveKey} placeholder="Enter Gemini API Key" className="w-full bg-white border-2 border-black p-3 font-mono text-sm mb-2" />
            <a href="https://aistudio.google.com/app/apikey" target="_blank" rel="noreferrer" className="text-xs underline text-blue-600">Get Key</a>
          </div>
        )}
        <div className="space-y-2">
          <label className="text-sm font-bold uppercase tracking-wide flex justify-between"><span>1. Source Material (Drag to Order)</span><span className="text-gray-500 text-xs">{images.length}/10 REELS</span></label>
          <div className="relative group">
            <input type="file" ref={fileInputRef} accept="image/*" multiple onChange={handleImageUpload} className="hidden" />
            <div className={`w-full border-4 border-black bg-gray-50 p-4 min-h-[200px] flex flex-col ${images.length === 0 ? 'items-center justify-center cursor-pointer hover:bg-gray-100' : ''}`}>
              {images.length === 0 ? (
                <div onClick={() => fileInputRef.current?.click()} className="flex flex-col items-center"><Camera className="w-12 h-12 mb-4 text-gray-400" /><span className="font-bold text-lg underline decoration-2 underline-offset-4">UPLOAD IMAGES</span><span className="text-xs mt-2 uppercase tracking-wide opacity-60">Up to 10 Files</span></div>
              ) : (
                <div className="w-full">
                    <div className="grid grid-cols-3 gap-2 mb-4">
                      {images.map((img, idx) => (
                        <div 
                            key={idx} 
                            draggable
                            onDragStart={() => handleDragStart(idx)}
                            onDragOver={handleDragOver}
                            onDrop={() => handleDrop(idx)}
                            className="relative aspect-square border-2 border-gray-200 bg-white cursor-grab active:cursor-grabbing hover:border-black transition-all"
                        >
                            <img src={img.url} alt={`reel-${idx}`} className="w-full h-full object-cover pointer-events-none" />
                            <div className="absolute bottom-0 left-0 bg-black text-white text-[10px] px-1 font-bold">{idx + 1}</div>
                            <button onClick={(e) => { e.stopPropagation(); removeImage(idx); }} className="absolute top-1 right-1 bg-black text-white p-1 hover:bg-red-600 z-10"><X className="w-3 h-3" /></button>
                        </div>
                      ))}
                      {images.length < 10 && <button onClick={() => fileInputRef.current?.click()} className="aspect-square border-2 border-dashed border-gray-300 flex items-center justify-center hover:bg-gray-200"><Plus className="w-6 h-6 text-gray-400" /></button>}
                    </div>
                    <button onClick={(e) => { e.stopPropagation(); clearImages(); }} className="text-xs font-bold text-red-600 uppercase w-full text-right">Clear Reel</button>
                </div>
              )}
            </div>
          </div>
        </div>
        <div className="space-y-4">
          <label className="text-sm font-bold uppercase tracking-wide">2. Distribution Platform</label>
          <div className="relative">
            <select value={platform} onChange={(e) => setPlatform(e.target.value)} className="w-full appearance-none bg-white border-2 border-black p-4 pr-10 font-bold focus:outline-none cursor-pointer hover:bg-gray-50">
              {platforms.map(p => <option key={p} value={p}>{p}</option>)}
            </select>
            <ChevronDown className="absolute right-4 top-1/2 -translate-y-1/2 w-5 h-5 pointer-events-none" />
          </div>
          <div className="bg-black text-white p-4 border-l-4 border-gray-400">
            <h4 className="font-bold uppercase text-xs mb-2 flex items-center gap-2"><Info className="w-3 h-3" /> {platformInfo[platform].title}</h4>
            <div className="grid grid-cols-2 gap-4 text-xs text-gray-300">
                <div><span className="text-gray-500 font-bold block">Superpower</span>{platformInfo[platform].bestFor}</div>
                <div><span className="text-gray-500 font-bold block">Pro Tip</span><span className="italic text-white">{platformInfo[platform].habit}</span></div>
            </div>
          </div>
        </div>
        <div className="space-y-2">
          <label className="text-sm font-bold uppercase tracking-wide">3. Director's Notes</label>
          <textarea value={userRequest} onChange={(e) => setUserRequest(e.target.value)} placeholder="E.g. 'Use the lighting from the first image, but change the subject to look like me in a vintage tuxedo.'" className="w-full h-32 border-2 border-black p-4 focus:outline-none focus:bg-black focus:text-white transition-colors resize-none bg-white placeholder:text-gray-400" />
        </div>
        <button onClick={generateOptimizedPrompt} disabled={loading} className="w-full py-5 bg-black text-white font-black text-xl uppercase tracking-wider border-2 border-black hover:bg-white hover:text-black transition-colors disabled:opacity-50 flex items-center justify-center gap-3 shadow-[8px_8px_0px_0px_rgba(128,128,128,0.5)] active:translate-x-[2px] active:translate-y-[2px] active:shadow-[4px_4px_0px_0px_rgba(128,128,128,0.5)]">
          {loading ? "Directing..." : "Action!"} {!loading && <Clapperboard className="w-6 h-6" />}
        </button>
        {error && <div className="p-4 border-l-4 border-red-600 bg-red-50 text-red-700 font-bold flex items-center gap-3"><AlertCircle className="w-6 h-6" />{error}</div>}
      </div>
      <div className="lg:col-span-7 flex flex-col h-full">
          {!result ? (
            <div className="h-full border-4 border-black bg-gray-50 flex flex-col items-center justify-center text-gray-400 p-10 text-center min-h-[400px]">
              <div className="w-24 h-24 border-4 border-black rounded-full flex items-center justify-center mb-6 bg-white text-black"><ImageIcon className="w-10 h-10" /></div>
              <h2 className="text-2xl font-black uppercase text-black mb-2 tracking-tight">Quiet on Set</h2>
              <p className="max-w-md font-medium">Upload up to 10 reference images, drag to reorder, select your platform, and provide notes to begin.</p>
            </div>
          ) : (
            <div className="flex flex-col gap-6 animate-in fade-in slide-in-from-bottom-4 duration-500">
              <div className="border-4 border-black bg-white shadow-[8px_8px_0px_0px_rgba(0,0,0,1)]">
                <div className="bg-black text-white p-4 flex justify-between items-center">
                  <h3 className="font-bold uppercase flex items-center gap-2 tracking-wider"><Command className="w-5 h-5" /> {platform} Script</h3>
                  <button onClick={() => copyText(result.prompt)} className="text-xs font-bold uppercase bg-white text-black px-3 py-1 hover:bg-gray-200 transition-colors flex items-center gap-2">{copied ? "COPIED!" : "COPY"}<Copy className="w-3 h-3" /></button>
                </div>
                <div className="p-6 text-base md:text-lg leading-relaxed font-mono whitespace-pre-wrap">{result.prompt}</div>
              </div>
              <div className="border-2 border-red-500 bg-red-50 p-6">
                <h4 className="flex items-center gap-2 text-red-600 font-black uppercase text-sm mb-3"><Wrench className="w-4 h-4" /> Troubleshoot Generation</h4>
                <p className="text-xs font-medium text-gray-700 mb-4">Result not what you wanted? Tell the AI what went wrong (e.g. "It ignored the camera angle" or "The subject looks like a cartoon"), and we will fix the script.</p>
                <div className="flex gap-2">
                    <input type="text" value={troubleInput} onChange={(e) => setTroubleInput(e.target.value)} placeholder="What is wrong with the image?" className="flex-grow border-2 border-red-200 p-2 text-sm focus:outline-none focus:border-red-500 bg-white" />
                    <button onClick={troubleshootPrompt} disabled={troubleLoading} className="bg-red-600 text-white px-4 py-2 font-bold uppercase text-xs hover:bg-red-700 disabled:opacity-50">{troubleLoading ? "Fixing..." : "Fix It"}</button>
                </div>
                {troubleResult && (
                    <div className="mt-4 p-4 bg-white border-2 border-red-200 animate-in fade-in">
                        <div className="mb-2"><span className="text-xs font-bold uppercase text-gray-500 block">Diagnosis</span><p className="text-sm font-medium">{troubleResult.diagnosis}</p></div>
                        <div className="mb-2"><span className="text-xs font-bold uppercase text-gray-500 block">The Fix</span><p className="text-sm font-medium text-green-600">{troubleResult.fix_action}</p></div>
                        <div className="bg-gray-100 p-3 font-mono text-xs border border-gray-300 mt-2 relative">{troubleResult.revised_prompt}<button onClick={() => copyText(troubleResult.revised_prompt)} className="absolute top-2 right-2 text-xs font-bold uppercase text-blue-600 hover:underline">Copy</button></div>
                    </div>
                )}
              </div>
              <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
                <div className="border-2 border-black bg-white p-6 flex flex-col">
                    <h3 className="font-black uppercase flex items-center gap-2 mb-4 text-sm tracking-wide border-b-2 border-black pb-2"><Lightbulb className="w-4 h-4" /> Director's Commentary</h3>
                    <p className="text-sm text-gray-800 leading-relaxed font-medium flex-grow">{result.reasoning}</p>
                </div>
                <div className="border-2 border-black bg-black text-white p-6 flex flex-col">
                    <h3 className="font-black uppercase flex items-center gap-2 mb-4 text-sm tracking-wide border-b-2 border-white pb-2"><GraduationCap className="w-4 h-4" /> Learning Review</h3>
                    <ul className="space-y-3 flex-grow">
                      {Array.isArray(result.takeaways) ? result.takeaways.map((tip, i) => <li key={i} className="text-sm flex items-start gap-3"><span className="min-w-[8px] h-[8px] bg-white mt-1.5 rotate-45" /><span className="text-gray-300 font-medium">{tip}</span></li>) : <li className="text-sm text-gray-300">{result.takeaways}</li>}
                    </ul>
                </div>
              </div>
            </div>
          )}
      </div>
    </div>
  );

  const GetTheLookView = () => (
    <div className="grid grid-cols-1 lg:grid-cols-12 gap-10 animate-in fade-in duration-500">
      <div className="lg:col-span-5 space-y-8">
        <div className="bg-black text-white p-6 border-4 border-gray-500">
            <h2 className="text-2xl font-black uppercase mb-2 flex items-center gap-2"><ScanEye className="w-6 h-6" /> Get The Look</h2>
            <p className="text-sm text-gray-300">Reverse-Engineer any image. Upload a photo, and we will extract its DNA (Lighting, Camera, Style) so you can recreate it.</p>
        </div>
        <div className="space-y-2">
          <label className="text-sm font-bold uppercase tracking-wide">Target Image</label>
          <div className="relative group">
            <input type="file" ref={lookInputRef} accept="image/*" onChange={handleLookUpload} className="hidden" />
            <div className={`w-full border-4 border-black bg-gray-50 p-4 min-h-[300px] flex flex-col ${!lookImage ? 'items-center justify-center cursor-pointer hover:bg-gray-100' : ''}`} onClick={() => !lookImage && lookInputRef.current?.click()}>
              {!lookImage ? (
                <div className="flex flex-col items-center"><ScanEye className="w-12 h-12 mb-4 text-gray-400" /><span className="font-bold text-lg underline decoration-2 underline-offset-4">UPLOAD TARGET</span><span className="text-xs mt-2 uppercase tracking-wide opacity-60">We will steal this look for you</span></div>
              ) : (
                <div className="relative w-full h-full">
                    <img src={lookImage} alt="Target" className="w-full h-full object-contain" />
                    <button onClick={(e) => { e.stopPropagation(); setLookImage(null); setLookBase64(null); setLookResult(null); }} className="absolute top-2 right-2 bg-black text-white p-2 hover:bg-red-600"><X className="w-4 h-4" /></button>
                </div>
              )}
            </div>
          </div>
        </div>
        <button onClick={analyzeLook} disabled={lookLoading} className="w-full py-5 bg-black text-white font-black text-xl uppercase tracking-wider border-2 border-black hover:bg-white hover:text-black transition-colors disabled:opacity-50 flex items-center justify-center gap-3 shadow-[8px_8px_0px_0px_rgba(128,128,128,0.5)] active:translate-x-[2px] active:translate-y-[2px] active:shadow-[4px_4px_0px_0px_rgba(128,128,128,0.5)]">
          {lookLoading ? "Analyzing DNA..." : "Extract Prompt"} {!lookLoading && <ArrowRight className="w-6 h-6" />}
        </button>
        {error && <div className="p-4 border-l-4 border-red-600 bg-red-50 text-red-700 font-bold flex items-center gap-3"><AlertCircle className="w-6 h-6" />{error}</div>}
      </div>
      <div className="lg:col-span-7 flex flex-col h-full">
          {!lookResult ? (
            <div className="h-full border-4 border-black bg-gray-50 flex flex-col items-center justify-center text-gray-400 p-10 text-center min-h-[400px]">
              <div className="w-24 h-24 border-4 border-black rounded-full flex items-center justify-center mb-6 bg-white text-black"><Unlock className="w-10 h-10" /></div>
              <h2 className="text-2xl font-black uppercase text-black mb-2 tracking-tight">Locked</h2>
              <p className="max-w-md font-medium">Upload an image to unlock its prompt formula.</p>
            </div>
          ) : (
            <div className="flex flex-col gap-6 animate-in fade-in slide-in-from-bottom-4 duration-500">
                <div className="border-4 border-black bg-white shadow-[8px_8px_0px_0px_rgba(0,0,0,1)]">
                    <div className="bg-black text-white p-4 flex justify-between items-center">
                        <h3 className="font-bold uppercase flex items-center gap-2 tracking-wider"><Key className="w-5 h-5" /> Master Prompt</h3>
                        <button onClick={() => copyText(lookResult.master_prompt)} className="text-xs font-bold uppercase bg-white text-black px-3 py-1 hover:bg-gray-200 transition-colors flex items-center gap-2">{copied ? "COPIED!" : "COPY"}<Copy className="w-3 h-3" /></button>
                    </div>
                    <div className="p-6 text-base md:text-lg leading-relaxed font-mono whitespace-pre-wrap">{lookResult.master_prompt}</div>
                </div>
                <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
                    <div className="border-2 border-black bg-white p-6">
                        <h3 className="font-black uppercase border-b-2 border-black pb-2 mb-4">Visual Breakdown</h3>
                        <ul className="space-y-4 text-sm">
                            <li><span className="font-bold block text-gray-500 text-xs uppercase">Subject</span> {lookResult.breakdown.subject}</li>
                            <li><span className="font-bold block text-gray-500 text-xs uppercase">Lighting</span> {lookResult.breakdown.lighting}</li>
                            <li><span className="font-bold block text-gray-500 text-xs uppercase">Camera/Lens</span> {lookResult.breakdown.camera}</li>
                            <li><span className="font-bold block text-gray-500 text-xs uppercase">Style</span> {lookResult.breakdown.style}</li>
                        </ul>
                    </div>
                    <div className="border-2 border-black bg-black text-white p-6">
                        <h3 className="font-black uppercase border-b-2 border-white pb-2 mb-4">Educational Note</h3>
                        <p className="text-sm leading-relaxed">{lookResult.education}</p>
                    </div>
                </div>
            </div>
          )}
      </div>
    </div>
  );

  const HowItWorksView = () => (
    <div className="max-w-5xl mx-auto space-y-12 animate-in fade-in slide-in-from-bottom-4">
        <div className="text-center mb-10"><h2 className="text-5xl font-black uppercase tracking-tighter mb-2">How It All Works</h2><p className="text-xl font-bold uppercase tracking-widest text-gray-400">Demystifying the Ghost in the Machine</p></div>
        <section className="bg-black text-white p-8 border-4 border-gray-500">
            <h3 className="text-2xl font-black uppercase mb-6 flex items-center gap-3"><Brain className="w-6 h-6" /> The Core Mechanic: Diffusion</h3>
            <div className="space-y-6 text-sm leading-relaxed text-gray-300">
                <p><strong className="text-white">Explanation:</strong> Imagine looking at a cloud and seeing a bunny. You squint, and it looks more like a bunny. You draw lines around it, and suddenly it IS a bunny. That is Diffusion.</p>
                <p>AI starts with "Noise" (static, like an old TV channel). It then mathematically "denoises" the image step-by-step, looking for patterns that match your text prompt. If you ask for a "Cat," it looks at the static and says, "That pixel looks like a whisker, let's keep it. That pixel looks like a car tire, delete it." It does this 20-50 times (Steps) until a clean image emerges.</p>
                <div className="bg-gray-900 p-4 border border-gray-700"><strong className="text-white block mb-2 uppercase text-xs">Example Setting: Steps</strong><p className="text-xs">If you set "Steps" to 5, the AI stops "squinting" too early, and the image is blurry. If you set it to 100, it might over-analyze and "burn" the image. 30 is usually the sweet spot.</p></div>
            </div>
        </section>
        <section className="border-4 border-black bg-white p-8">
            <h3 className="text-2xl font-black uppercase mb-6 flex items-center gap-3"><Globe className="w-6 h-6" /> The Library: Latent Space</h3>
            <div className="space-y-6 text-sm leading-relaxed text-gray-700">
                <p><strong className="text-black">Explanation:</strong> AI doesn't know what a "Cat" looks like visually. It knows the *mathematical concept* of a cat. Imagine a giant 3D map of the universe. In one corner, all "Furry things" live. In another, "Metal things."</p>
                <p>When you prompt "Cyborg Cat," the AI draws a line between the "Furry" corner and the "Metal" corner and finds the image that exists exactly in the middle. This map is called <strong>Latent Space</strong>.</p>
                <p>Embedding: This is the process of translating your English text into coordinates on that map. If your prompt is vague ("Cool guy"), the AI aims at a huge, blurry region of the map. If your prompt is specific ("Man in tuxedo, 85mm lens, rim lighting"), you give the AI exact GPS coordinates.</p>
            </div>
        </section>
        <div className="grid grid-cols-1 md:grid-cols-2 gap-8">
            <section className="border-2 border-black bg-white p-6"><h3 className="text-xl font-black uppercase mb-4 flex items-center gap-2"><Sparkles className="w-5 h-5" /> Text-to-Image (T2I)</h3><p className="text-xs font-bold text-gray-500 uppercase mb-4">Creating from Nothing</p><p className="text-sm text-gray-600 mb-4">You give text. The AI starts with 100% random static noise. It hallucinates an image purely based on your words.</p><p className="text-sm font-bold">Best For:</p><ul className="list-disc pl-4 text-xs text-gray-600 space-y-1"><li>Creating concepts that don't exist.</li><li>Surrealism.</li><li>When you don't have a reference photo.</li></ul></section>
            <section className="border-2 border-black bg-white p-6"><h3 className="text-xl font-black uppercase mb-4 flex items-center gap-2"><ImageIcon className="w-5 h-5" /> Image-to-Image (I2I)</h3><p className="text-xs font-bold text-gray-500 uppercase mb-4">Guiding the Dream</p><p className="text-sm text-gray-600 mb-4">You give an image + text. The AI doesn't start with random static; it starts with *your* image (turned slightly into static). It then rebuilds it using your text prompt.</p><div className="bg-gray-100 p-3 border border-gray-300 mt-4"><strong className="block mb-1 text-xs uppercase">Key Setting: Denoising Strength</strong><p className="text-xs text-gray-500"><strong>Low (0.3):</strong> "Keep my image, just change the colors slightly."<br/><strong>High (0.8):</strong> "Use my image as a rough suggestion, but change almost everything."</p></div></section>
        </div>
        <section className="border-4 border-black bg-gray-50 p-8">
             <h3 className="text-2xl font-black uppercase mb-6 flex items-center gap-3"><Cpu className="w-6 h-6" /> Model DNA: Why they look different</h3>
             <div className="space-y-8">
                 <div><h4 className="font-bold text-lg uppercase mb-2">Midjourney: The Painter</h4><p className="text-sm text-gray-700">Midjourney is trained on beautiful art, not just photos. It has a strong "aesthetic bias." Even if you write a bad prompt, it tries to make it look pretty. It prioritizes texture, lighting, and composition over logic. <strong>Best for:</strong> Cinematic shots, posters, fantasy.</p></div>
                 <hr className="border-gray-300"/>
                 <div><h4 className="font-bold text-lg uppercase mb-2">Flux / Stable Diffusion: The Architect</h4><p className="text-sm text-gray-700">These are "literal" models. They don't care if the image is pretty; they care if it follows your instructions. If you ask for a "ugly dog," Midjourney might make a cute ugly dog. Flux will make a hideous dog. <strong>Best for:</strong> Photorealism, text rendering, exact instruction following.</p></div>
                 <hr className="border-gray-300"/>
                 <div><h4 className="font-bold text-lg uppercase mb-2">DALL-E 3: The Translator</h4><p className="text-sm text-gray-700">DALL-E is powered by ChatGPT. It understands language nuances better than any other. It can handle complex logic like "A cat sitting on a box that is inside a bigger box." Other models struggle with spatial relationships; DALL-E gets them right. <strong>Best for:</strong> Complex scenes, typography, logic.</p></div>
             </div>
        </section>
    </div>
  );

  const VaultView = () => (
    <div className="max-w-6xl mx-auto space-y-12 animate-in fade-in slide-in-from-bottom-4">
        <div className="text-center mb-10"><h2 className="text-5xl font-black uppercase tracking-tighter mb-2">The Vault</h2><p className="text-xl font-bold uppercase tracking-widest text-gray-400">The Encyclopedia of Light</p></div>
        <section className="border-4 border-black bg-white p-8">
            <h3 className="text-2xl font-black uppercase mb-6 flex items-center gap-3"><Key className="w-6 h-6" /> The Pocket Formula</h3>
            <p className="text-gray-600 mb-6 font-medium">Don't know where to start? Use this sentence structure for consistent results on 99% of AI models.</p>
            <div className="bg-gray-100 p-6 rounded-lg font-mono text-sm md:text-base border-2 border-gray-300">
                <span className="text-blue-600 font-bold">[Subject]</span> doing <span className="text-green-600 font-bold">[Action]</span> in <span className="text-purple-600 font-bold">[Context/Setting]</span>, shot on <span className="text-orange-600 font-bold">[Film Stock/Camera]</span> with <span className="text-red-600 font-bold">[Lighting Style]</span> lighting. <span className="text-gray-500 font-bold">--ar 16:9</span>
            </div>
        </section>
        <section className="border-4 border-black bg-gray-50 p-8">
             <h3 className="text-2xl font-black uppercase mb-6 flex items-center gap-3"><Sliders className="w-6 h-6" /> The Rosetta Stone (Parameter Guide)</h3>
             <p className="text-sm text-gray-600 mb-8">Parameters are the volume knobs of AI. We break down the Good vs. Bad usage for each model.</p>
            <div className="space-y-8">
                 <div className="bg-white border-2 border-black p-6">
                    <h4 className="text-xl font-black uppercase border-b-2 border-black pb-2 mb-4">Midjourney v6</h4>
                    <div className="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
                        <div className="bg-red-50 border-2 border-red-200 p-4"><h5 className="flex items-center gap-2 font-bold text-red-600 uppercase text-xs mb-2"><XCircle className="w-4 h-4" /> The Bad Example</h5><p className="font-mono text-xs text-gray-600 mb-2">"A cool picture of a cyberpunk city at night, realistic"</p><p className="text-xs font-medium text-red-800"><strong>Why it fails:</strong> "Cool" and "Realistic" are subjective. Without parameters, MJ defaults to a generic square (1:1) art style.</p></div>
                        <div className="bg-green-50 border-2 border-green-200 p-4"><h5 className="flex items-center gap-2 font-bold text-green-600 uppercase text-xs mb-2"><CheckCircle className="w-4 h-4" /> The Perfect Example</h5><p className="font-mono text-xs text-gray-600 mb-2">"Futuristic Tokyo street level, neon rain reflection, 35mm lens --ar 16:9 --stylize 250 --v 6.0"</p><p className="text-xs font-medium text-green-800"><strong>Why it works:</strong> <span className="font-bold">--ar 16:9</span> sets a cinematic shape. <span className="font-bold">--stylize 250</span> adds artistic flair without losing realism.</p></div>
                    </div>
                    <ul className="text-xs space-y-2 text-gray-700 border-t pt-4"><li><span className="font-bold text-black">--stylize (0-1000)</span>: 0 is literal (boring). 1000 is artistic (chaotic). 250 is the sweet spot.</li><li><span className="font-bold text-black">--weird (0-3000)</span>: Adds "strange" logic. Use for dream sequences.</li></ul>
                 </div>
                 <div className="bg-white border-2 border-black p-6">
                    <h4 className="text-xl font-black uppercase border-b-2 border-black pb-2 mb-4">Flux.1 / Stable Diffusion</h4>
                    <div className="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
                        <div className="bg-red-50 border-2 border-red-200 p-4"><h5 className="flex items-center gap-2 font-bold text-red-600 uppercase text-xs mb-2"><XCircle className="w-4 h-4" /> The Bad Example</h5><p className="font-mono text-xs text-gray-600 mb-2">"Portrait of a girl, blue hat, red scarf"</p><p className="text-xs font-medium text-red-800"><strong>Why it fails:</strong> "Color Bleeding". The AI might make the hat red or the scarf blue because it confuses the tokens.</p></div>
                        <div className="bg-green-50 border-2 border-green-200 p-4"><h5 className="flex items-center gap-2 font-bold text-green-600 uppercase text-xs mb-2"><CheckCircle className="w-4 h-4" /> The Perfect Example</h5><p className="font-mono text-xs text-gray-600 mb-2">"Portrait of a girl, (blue hat:1.2), (red scarf:1.1), sharp focus, 8k"</p><p className="text-xs font-medium text-green-800"><strong>Why it works:</strong> <span className="font-bold">Parentheses</span> isolate the objects. <span className="font-bold">:1.2</span> increases the importance (weight) of that specific color staying with that object.</p></div>
                    </div>
                    <ul className="text-xs space-y-2 text-gray-700 border-t pt-4"><li><span className="font-bold text-black">CFG Scale (7)</span>: A "Listening" slider. Low (3) = It ignores you. High (15) = It obeys strictly (can burn the image).</li></ul>
                 </div>
                 <div className="bg-white border-2 border-black p-6">
                    <h4 className="text-xl font-black uppercase border-b-2 border-black pb-2 mb-4">DALL-E 3 / Gemini</h4>
                    <div className="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
                        <div className="bg-red-50 border-2 border-red-200 p-4"><h5 className="flex items-center gap-2 font-bold text-red-600 uppercase text-xs mb-2"><XCircle className="w-4 h-4" /> The Bad Example</h5><p className="font-mono text-xs text-gray-600 mb-2">"4k, hd, unreal engine, octane render, trending on artstation"</p><p className="text-xs font-medium text-red-800"><strong>Why it fails:</strong> "Keyword Stuffing". Modern conversational models hate this. They interpret it as noise, not instruction.</p></div>
                        <div className="bg-green-50 border-2 border-green-200 p-4"><h5 className="flex items-center gap-2 font-bold text-green-600 uppercase text-xs mb-2"><CheckCircle className="w-4 h-4" /> The Perfect Example</h5><p className="font-mono text-xs text-gray-600 mb-2">"A wide shot of a knight standing in a field. The lighting is moody and overcast. The texture should look like a 1980s dark fantasy movie."</p><p className="text-xs font-medium text-green-800"><strong>Why it works:</strong> Conversational clarity. You are describing the *vibe* and *composition* in plain English.</p></div>
                    </div>
                 </div>
            </div>
        </section>
        <section className="grid grid-cols-1 md:grid-cols-2 gap-8">
            <div className="border-2 border-black bg-white p-6">
                <h3 className="text-xl font-black uppercase mb-4 flex items-center gap-2"><Camera className="w-5 h-5" /> Camera Color Science</h3>
                <ul className="space-y-4 text-sm">
                    <li><span className="font-bold block">Canon (R5 / 5D)</span><span className="text-gray-600"><strong>The "Portrait" Look.</strong> Canon adds warmth (red/magenta). It makes skin look healthy and soft.</span></li>
                    <li><span className="font-bold block">Sony (A7R IV)</span><span className="text-gray-600"><strong>The "Technical" Look.</strong> Clinical sharpness, cool tones. Best for architecture or detailed textures.</span></li>
                    <li><span className="font-bold block">Fujifilm (GFX 100)</span><span className="text-gray-600"><strong>The "Vibe" Look.</strong> Emphasizes greens/blues. Instant nostalgia. Use for street photography.</span></li>
                </ul>
            </div>
            <div className="border-2 border-black bg-white p-6">
                <h3 className="text-xl font-black uppercase mb-4 flex items-center gap-2"><Aperture className="w-5 h-5" /> Lens Theory</h3>
                <ul className="space-y-4 text-sm">
                    <li><span className="font-bold block">16mm (Wide)</span><span className="text-gray-600"><strong>Exaggeration.</strong> Distorts edges. Makes epic landscapes look huge.</span></li>
                    <li><span className="font-bold block">35mm - 50mm (Neutral)</span><span className="text-gray-600"><strong>Honesty.</strong> How the human eye sees. No distortion. Documentary style.</span></li>
                    <li><span className="font-bold block">85mm (Portrait)</span><span className="text-gray-600"><strong>Compression.</strong> Flattens the face (making it prettier) and blurs the background.</span></li>
                </ul>
            </div>
        </section>
        <section className="bg-black text-white p-8 border-4 border-gray-200">
             <h3 className="text-xl font-black uppercase mb-6 flex items-center gap-2"><Eye className="w-5 h-5" /> The Hierarchy of Realism</h3>
            <div className="grid grid-cols-1 md:grid-cols-4 gap-4 text-center">
                <div className="p-4 border border-gray-700 bg-gray-900"><div className="font-black text-lg mb-2 text-blue-400">Photorealistic</div><div className="text-xs text-gray-300">A standard photo. Accepts flaws/messiness. Feels authentic.</div></div>
                <div className="p-4 border border-gray-700 bg-gray-900"><div className="font-black text-lg mb-2 text-purple-400">Hyperrealistic</div><div className="text-xs text-gray-300">More real than life. Every texture sharpened. Advertising/CGI look.</div></div>
                <div className="p-4 border border-gray-700 bg-gray-900"><div className="font-black text-lg mb-2 text-green-400">8K / RAW</div><div className="text-xs text-gray-300">"Information Tokens". Forces the AI to fill empty space with micro-details (dust, pores).</div></div>
                <div className="p-4 border border-gray-700 bg-gray-900"><div className="font-black text-lg mb-2 text-orange-400">Unreal Engine 5</div><div className="text-xs text-gray-300">Digital Perfection. Perfect ray-traced lighting. Best for Sci-Fi/Gaming.</div></div>
            </div>
        </section>
    </div>
  );

  const ContactView = () => (
    <div className="max-w-3xl mx-auto space-y-10 animate-in fade-in slide-in-from-bottom-4">
        <div className="text-center mb-10"><h2 className="text-5xl font-black uppercase tracking-tighter mb-2">Reach Out</h2><p className="text-xl font-bold uppercase tracking-widest text-gray-400">Contact the Studio</p></div>
        <div className="bg-white border-4 border-black p-8 shadow-[12px_12px_0px_0px_rgba(0,0,0,1)]">
            <form onSubmit={handleContactSubmit} className="space-y-6">
                <div><label className="block text-xs font-black uppercase tracking-wide mb-2">Your Name</label><input type="text" required value={contactName} onChange={(e) => setContactName(e.target.value)} className="w-full border-2 border-gray-200 p-3 text-sm focus:border-black focus:outline-none transition-colors" placeholder="Jane Doe" /></div>
                <div><label className="block text-xs font-black uppercase tracking-wide mb-2">Your Email</label><input type="email" required value={contactEmail} onChange={(e) => setContactEmail(e.target.value)} className="w-full border-2 border-gray-200 p-3 text-sm focus:border-black focus:outline-none transition-colors" placeholder="jane@example.com" /></div>
                <div><label className="block text-xs font-black uppercase tracking-wide mb-2">Subject</label><input type="text" required value={contactSubject} onChange={(e) => setContactSubject(e.target.value)} className="w-full border-2 border-gray-200 p-3 text-sm focus:border-black focus:outline-none transition-colors" placeholder="Question about Pocket Cinema..." /></div>
                <div><label className="block text-xs font-black uppercase tracking-wide mb-2">Context / Message</label><textarea required value={contactMessage} onChange={(e) => setContactMessage(e.target.value)} className="w-full border-2 border-gray-200 p-3 text-sm focus:border-black focus:outline-none transition-colors h-40 resize-none" placeholder="How can we help?" /></div>
                <button type="submit" className="w-full bg-black text-white py-4 font-black uppercase tracking-widest hover:bg-gray-800 transition-colors flex items-center justify-center gap-2">Reach Out <Send className="w-4 h-4" /></button>
            </form>
            <div className="mt-6 text-center"><p className="text-xs text-gray-400">This form will open your default email client with your message pre-formatted.</p></div>
        </div>
    </div>
  );

  const AboutView = () => (
    <div className="max-w-3xl mx-auto space-y-10 animate-in fade-in slide-in-from-bottom-4">
      <div className="border-4 border-black p-8 bg-white shadow-[12px_12px_0px_0px_rgba(0,0,0,1)]">
        <h2 className="text-4xl font-black uppercase tracking-tighter mb-6">About The App</h2>
        <p className="text-lg font-medium leading-relaxed mb-6"><span className="font-black">ImaginPrompt</span> (Pocket Cinema Edition) is a professional-grade prompt engineering utility designed for filmmakers, photographers, and creative directors using AI.</p>
        <p className="text-gray-600 mb-6">Unlike standard generators, this tool acts as a <strong>"Visual Director"</strong>. It doesn't just look at your image; it analyzes the lighting ratios, camera focal lengths, and compositional geometry to write a prompt that speaks the native language of your chosen AI platform.</p>
      </div>
      <div className="space-y-4">
        <h3 className="text-2xl font-black uppercase tracking-tight border-b-4 border-black pb-2">Release Notes</h3>
        <div className="bg-gray-50 border-2 border-black p-6">
            <div className="flex justify-between items-start mb-4"><h4 className="font-bold text-xl">Version 7.0</h4><span className="bg-black text-white px-3 py-1 text-xs font-bold uppercase">The Architect Edition</span></div>
            <ul className="space-y-2 text-sm font-medium text-gray-700">
                <li> <strong>AI GLOSSARY:</strong> A comprehensive A-Z list of every technical term, explained in plain English.</li>
                <li> <strong>DRAG & DROP REELS:</strong> You can now drag your uploaded reference images to reorder priority.</li>
                <li> <strong>NEW TAB: HOW IT WORKS.</strong> A deep-dive educational section on Diffusion, Latent Space, and Model mechanics.</li>
                <li> <strong>GET THE LOOK:</strong> Reverse-engineer any photo into a master prompt.</li>
                <li> <strong>ROSETTA STONE V3:</strong> Good vs. Bad prompt examples for every model.</li>
            </ul>
        </div>
      </div>
    </div>
  );

  const Top10View = () => (
    <div className="max-w-4xl mx-auto space-y-8 animate-in fade-in slide-in-from-bottom-4">
        <div className="text-center mb-12">
            <h2 className="text-5xl font-black uppercase tracking-tighter mb-2">The Top 10</h2>
            <p className="text-xl font-bold uppercase tracking-widest text-gray-400">Text-to-Image with Attachment Capability</p>
            <div className="inline-block bg-black text-white px-4 py-2 mt-4 font-mono text-sm">GENERATED: {GENERATION_DATE}</div>
            <p className="mt-6 text-sm max-w-lg mx-auto font-medium text-gray-600">Pocket Cinema believes that creativity should not be gated by wealth. For every paid tool listed below, we have provided a free workaround.</p>
        </div>
        <div className="grid gap-8">
            {top10List.map((item) => (
                <div key={item.rank} className="border-4 border-black bg-white hover:shadow-[8px_8px_0px_0px_rgba(0,0,0,1)] transition-shadow">
                    <div className="flex justify-between items-stretch border-b-2 border-black bg-gray-50">
                        <div className="flex items-center"><div className="bg-black text-white w-12 h-full min-h-[50px] flex items-center justify-center font-black text-2xl">#{item.rank}</div><div className="px-4 py-2"><h3 className="text-xl font-black uppercase leading-none flex items-center gap-2">{item.name}{item.localInfo && <Monitor className="w-4 h-4 text-gray-500" />}</h3><span className="text-xs font-bold text-gray-500 uppercase">{item.type}</span></div></div>
                        <div className={`px-4 flex flex-col justify-center items-end border-l-2 border-black min-w-[120px] ${item.status.includes("FREE") ? "bg-green-100" : "bg-red-50"}`}><span className="text-xs font-black uppercase tracking-wide">{item.status}</span><span className="text-[10px] font-bold text-gray-600">{item.cost}</span></div>
                    </div>
                    <div className="p-6">
                        <p className="text-sm font-medium text-gray-800 leading-relaxed mb-6">{item.why}</p>
                        {item.localInfo && (
                            <div className="mb-6 p-4 border-2 border-dashed border-gray-300 bg-gray-50 rounded-lg"><h4 className="flex items-center gap-2 text-xs font-black uppercase text-gray-600 mb-2"><Cpu className="w-3 h-3" /> Technical Note: Running Locally</h4><p className="text-xs text-gray-600 leading-relaxed mb-3">{item.localInfo}</p><div className="flex flex-wrap gap-2">{item.localLinks && item.localLinks.map((link, i) => (<a key={i} href={link.url} target="_blank" rel="noreferrer" className="flex items-center gap-1 bg-gray-200 hover:bg-gray-300 px-3 py-1.5 rounded text-[10px] font-bold uppercase transition-colors"><Download className="w-3 h-3" /> {link.label}</a>))}</div></div>
                        )}
                        <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                            <a href={item.url} target="_blank" rel="noreferrer" className="flex items-center justify-center gap-2 bg-white border-2 border-black py-3 px-4 text-xs font-bold uppercase hover:bg-gray-100 transition-colors h-full">Go To Source <ExternalLink className="w-3 h-3" /></a>
                            <div className="bg-black text-white p-4 border-l-4 border-gray-400"><div className="flex items-center gap-2 mb-3 text-xs font-bold uppercase tracking-widest text-green-400"><Unlock className="w-3 h-3" /> Pocket Workaround</div><p className="text-xs font-medium leading-relaxed text-gray-300 mb-3">{item.workaround}</p><div className="flex flex-wrap gap-2">{item.workaroundLinks && item.workaroundLinks.map((link, i) => (<a key={i} href={link.url} target="_blank" rel="noreferrer" className="flex items-center gap-1 bg-gray-800 hover:bg-gray-700 text-white px-3 py-1.5 rounded border border-gray-600 text-[10px] font-bold uppercase transition-colors">{link.label} <ArrowRight className="w-3 h-3" /></a>))}</div></div>
                        </div>
                    </div>
                </div>
            ))}
        </div>
        <div className="text-center text-xs text-gray-400 uppercase font-bold mt-10">*Rankings based on image-to-image fidelity and accessibility.</div>
    </div>
  );

  const WhoIsView = () => (
    <div className="max-w-3xl mx-auto animate-in fade-in slide-in-from-bottom-4">
       <div className="border-l-8 border-black pl-8 py-4 mb-12"><h2 className="text-5xl font-black uppercase tracking-tighter mb-2">Who We Are</h2><p className="font-bold text-gray-500 uppercase tracking-widest">Pocket Cinema x Nathan Histed</p></div>
       <div className="prose prose-lg prose-headings:font-black prose-headings:uppercase prose-p:font-medium prose-p:text-gray-800 max-w-none">
            <div className="space-y-12">
                <section><h3 className="text-2xl border-b-4 border-black pb-2 mb-4">About Pocket Cinema</h3><p>Pocket Cinema is a phone-first cinematic storytelling studio and creative methodology built around ethical, restrained use of artificial intelligence. We exist to show how AI can function as a cinematic tool rather than a spectacle  prioritizing realism, emotional truth, and long-term craft over hype, speed, or virality.</p><p className="font-black mt-4">If it works on a phone, it works anywhere.</p></section>
                <section><h3 className="text-2xl border-b-4 border-black pb-2 mb-4">Who We Are</h3><p>Pocket Cinema is founded on the belief that technology should serve storytelling, not overshadow it. We are creators, directors, and builders who treat AI the same way filmmakers treat a camera: as an instrument guided by human intent, taste, and responsibility.</p><p>Pocket Cinema is not a trend project or a content experiment. It is a growing body of work designed to accumulate meaning over time.</p></section>
                <section><h3 className="text-2xl border-b-4 border-black pb-2 mb-4">What We Do</h3><p>We create cinematic experiences, tools, and workflows that help people:</p><ul className="list-disc pl-5 space-y-2 mt-4 marker:text-black"><li>Tell grounded, emotionally honest stories using AI</li><li>Preserve memory and identity with care and permission</li><li>Build cinematic visuals without expensive equipment</li><li>Learn AI through structure, restraint, and repeatable process</li></ul><p className="mt-4">All Pocket Cinema workflows are designed to be accessible, phone-first, and tool-agnostic.</p></section>
                <section><h3 className="text-2xl border-b-4 border-black pb-2 mb-4">Core Beliefs</h3><ul className="list-disc pl-5 space-y-2 marker:text-black"><li>AI should be treated like a camera, not a magician</li><li>Restraint produces stronger work than excess</li><li>Identity and memory are more important than novelty</li><li>Tools change, but taste and intention last</li><li>Transparency and ethics are part of craft, not optional features</li></ul></section>
                <section><h3 className="text-2xl border-b-4 border-black pb-2 mb-4">Values</h3><div className="grid gap-6"><div><span className="block font-black uppercase text-sm mb-1">Ethics First</span><p className="text-sm">We do not use deceptive deepfakes, distort identity, or exploit likeness. Only permitted material or the creators own likeness is used, with full transparency.</p></div><div><span className="block font-black uppercase text-sm mb-1">Accessibility</span><p className="text-sm">High-quality cinematic work should not be gated by expensive gear, complex software, or exclusive access.</p></div><div><span className="block font-black uppercase text-sm mb-1">Restraint Over Hype</span><p className="text-sm">We value clarity, calm, and intention over spectacle, trends, or algorithm chasing.</p></div><div><span className="block font-black uppercase text-sm mb-1">Sustainability</span><p className="text-sm">Pocket Cinema is built to support long-term creative health  mentally, creatively, and ethically.</p></div><div><span className="block font-black uppercase text-sm mb-1">Trust</span><p className="text-sm">Monetization is optional, pressure-free, and never compromises the integrity of the work or the audience relationship.</p></div></div></section>
                <section className="bg-black text-white p-8 text-center mt-12"><p className="text-lg font-bold uppercase tracking-widest leading-relaxed">Pocket Cinema grows through accumulation, not virality.<br/>This is cinematic AI, made on a phone.</p></section>
            </div>
       </div>
    </div>
  );

  return (
    <div className="min-h-screen bg-white text-black font-sans selection:bg-black selection:text-white">
      <Navigation />
      <div className="max-w-7xl mx-auto px-6 py-10">
        {currentView === 'generator' && <GeneratorView />}
        {currentView === 'get-look' && <GetTheLookView />}
        {currentView === 'how-it-works' && <HowItWorksView />}
        {currentView === 'glossary' && <GlossaryView />}
        {currentView === 'vault' && <VaultView />}
        {currentView === 'about' && <AboutView />}
        {currentView === 'top10' && <Top10View />}
        {currentView === 'whois' && <WhoIsView />}
        {currentView === 'contact' && <ContactView />}
      </div>
      <footer className="max-w-7xl mx-auto px-6 mt-20 pt-10 border-t-2 border-gray-100 flex flex-col md:flex-row justify-between items-center gap-4 text-gray-400 text-sm font-medium uppercase tracking-widest pb-10">
        <div> 2025 Pocket Cinema x Nathan Histed</div>
        <div className="flex gap-6"><span>Version 7.0</span><span>The Architect Edition</span></div>
      </footer>
    </div>
  );
};

export default PocketCinemaApp;


